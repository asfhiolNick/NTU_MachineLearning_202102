{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "「「ML2022Spring - HW8.ipynb」的副本」的副本",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiVfKn-6tXz8"
      },
      "source": [
        "# **Homework 8 - Anomaly Detection**\n",
        "\n",
        "If there are any questions, please contact mlta-2022spring-ta@googlegroups.com\n",
        "\n",
        "Slide:    [Link]()　Kaggle: [Link](https://www.kaggle.com/c/ml2022spring-hw8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDk9r2YOcDc9"
      },
      "source": [
        "# Set up the environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi12tJMYWi0Q"
      },
      "source": [
        "## Package installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCgNXSsEWuY7"
      },
      "source": [
        "## Downloading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNe7QU7n7cqh"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "firstTime = False\n",
        "ensemblePart = 1\n",
        "coderType = 0\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXbfNlGS9Col",
        "outputId": "b2a381b0-aa3b-4213-c5ca-75f7b5354d73"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May  8 03:41:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LexxyPWWjJB"
      },
      "source": [
        "if firstTime:\n",
        "  !pip install -q qqdm\n",
        "  !wget https://github.com/MachineLearningHW/HW8_Dataset/releases/download/v1.0.0/data.zip\n",
        "  !unzip data.zip\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision.models as models\n",
        "from torch.optim import Adam, AdamW\n",
        "from qqdm import qqdm, format_str\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X6fkGPnYyaF"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Wd4yiUYzAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e357df8-6f93-4e55-f658-416637e5a065"
      },
      "source": [
        "\n",
        "train = np.load('data/trainingset.npy', allow_pickle=True)\n",
        "test = np.load('data/testingset.npy', allow_pickle=True)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(19636, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_flpmj6OYIa6"
      },
      "source": [
        "## Random seed\n",
        "Set the random seed to a certain value for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb-dgXQYYI2Q"
      },
      "source": [
        "def same_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(48763)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR9zC0_Df-CR"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EbfwRREhA7c"
      },
      "source": [
        "# Models & loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "import tensorflow as tf \n",
        "class all(nn.Module) :\n",
        "    def contracting_block(self, in_channels, out_channels, ker_size):\n",
        "        block = torch.nn.Sequential(\n",
        "                    nn.Conv2d(in_channels, out_channels, ker_size, stride=2, padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.BatchNorm2d(out_channels),\n",
        "                    nn.Conv2d(out_channels, out_channels, ker_size),\n",
        "                    nn.ReLU(),\n",
        "                    nn.BatchNorm2d(out_channels),\n",
        "                )\n",
        "        return block\n",
        "\n",
        "    def __init__(self):\n",
        "        super(all, self).__init__()\n",
        "        self.t1_encoder = nn.Sequential(\n",
        "            nn.Linear(64 * 64 * 3, 1024*3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024*3, 256*3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256*3, 64*3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64*3, 16*3),\n",
        "            nn.ReLU(), \n",
        "            nn.Linear(16*3, 8*3),\n",
        "        )    \n",
        "        self.t3_encoder = nn.Sequential(\n",
        "            self.contracting_block(3, 6, 2),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            self.contracting_block(6, 12, 2),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            self.contracting_block(12, 24, 2),\n",
        "            nn.MaxPool2d(kernel_size=2),   \n",
        "        )\n",
        "        self.t5_encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 28, kernel_size=4, stride=2),    #(64-3)/2=31\n",
        "            nn.PReLU(),  \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),        #(31-1)/2=15\n",
        "            nn.Conv2d(28, 48, kernel_size=2, stride=1),   #(15-1)/1=14\n",
        "            nn.PReLU(),  \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),        #(14-1)/2=7\n",
        "            nn.Conv2d(48, 64, kernel_size=2, stride=1),   #(7-1)/1=6\n",
        "            nn.PReLU()  \n",
        "        )\n",
        "        self.t5_linear = nn.Sequential(\n",
        "            nn.Linear(64 * 6 * 6, 256), \n",
        "            nn.PReLU(),\n",
        "            nn.Linear(256, 24),\n",
        "        )\n",
        "        self.t1_decoder = nn.Sequential(\n",
        "            nn.Linear(8*3, 16*3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16*3, 64*3),\n",
        "            nn.ReLU(), \n",
        "            nn.Linear(64*3, 256*3),\n",
        "            nn.ReLU(), \n",
        "            nn.Linear(256*3, 1024*3),\n",
        "            nn.ReLU(), \n",
        "            nn.Linear(1024*3, 4096*3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        imgf = img.view(img.shape[0], -1)\n",
        "        img1 = self.t1_encoder(imgf)\n",
        "        global ensemblePart\n",
        "\n",
        "        if ensemblePart == 0:\n",
        "          img3 = self.t3_encoder(img)\n",
        "          img3 = img3[:,:,0,0]\n",
        "          x = (img1+img3)/2\n",
        "          x = self.t1_decoder(x)\n",
        "\n",
        "        elif ensemblePart == 1:\n",
        "          img5 = self.t5_encoder(img)\n",
        "          img5 = img5.view(img5.shape[0], img5.shape[1]*img5.shape[2]*img5.shape[3])\n",
        "          img5 = self.t5_linear(img5)\n",
        "          x = (img1+img5)/2\n",
        "          x = self.t1_decoder(x)\n",
        "        return x          "
      ],
      "metadata": {
        "id": "LfbRKMP5cddC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrJ9bScg9AgO"
      },
      "source": [
        "# Dataset module\n",
        "\n",
        "Module for obtaining and processing data. The transform function here normalizes image's pixels from [0, 255] to [-1.0, 1.0].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33fWhE-h9LPq"
      },
      "source": [
        "class CustomTensorDataset(TensorDataset):\n",
        "    \"\"\"TensorDataset with support of transforms.\n",
        "    \"\"\"\n",
        "    def __init__(self, tensors):\n",
        "        self.tensors = tensors\n",
        "        if tensors.shape[-1] == 3:\n",
        "            self.tensors = tensors.permute(0, 3, 1, 2)\n",
        "        \n",
        "        self.transform = transforms.Compose([\n",
        "          transforms.Lambda(lambda x: x.to(torch.float32)),\n",
        "          transforms.Lambda(lambda x: 2. * x/255. - 1.),\n",
        "        ])\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            # mapping images to [-1.0, 1.0]\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tensors)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKNUImqUhIeq"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XQlW6maQvo5A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ebAJdjFmS08"
      },
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in7yLfmqtZTk"
      },
      "source": [
        "# Training hyperparameters\n",
        "num_epochs = 10#100\n",
        "batch_size = 2000\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Build training dataloader\n",
        "x = torch.from_numpy(train)\n",
        "train_dataset = CustomTensorDataset(x)\n",
        "\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Model\n",
        "model_type = 'all'   # selecting a model type from {'cnn', 'fcn', 'vae', 'resnet'}\n",
        "model_classes = {'all': all()}\n",
        "model = model_classes[model_type].cuda()\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=6, eta_min=0, last_epoch=-1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyooN-JPm8sS"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoW1UrrxgI_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d6b828-16a0-4adf-dcc7-4c7af94db269"
      },
      "source": [
        "best_loss = np.inf\n",
        "model.train()\n",
        "\n",
        "qqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))\n",
        "for epoch in qqdm_train:\n",
        "    tot_loss = list()\n",
        "    for data in train_dataloader:\n",
        "        img = data.float().cuda()\n",
        "\n",
        "        output = model(img)\n",
        "        if model_type in ['all'] and coderType == 0:\n",
        "            img = img.view(img.shape[0], -1)\n",
        "        \n",
        "        loss = criterion(output, img)\n",
        "        tot_loss.append(loss.item())\n",
        "        # ===================backward====================\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    #scheduler.step()\n",
        "    # ===================save_best====================\n",
        "    mean_loss = np.mean(tot_loss)\n",
        "    if mean_loss < best_loss:\n",
        "        best_loss = mean_loss\n",
        "        torch.save(model, 'best_model_{}.pt'.format(model_type))\n",
        "    # ===================log========================\n",
        "    qqdm_train.set_infos({\n",
        "        'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',\n",
        "        'loss': f'{mean_loss:.4f}',\n",
        "    })\n",
        "    # ===================save_last========================\n",
        "    torch.save(model, 'last_model_{}.pt'.format(model_type))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m                                               \n",
            " \u001b[99m0/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m        -        \u001b[0m  \u001b[99m   -    \u001b[0m                                             \n",
            "\u001b[1mDescription\u001b[0m   0.0% |                                                           |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m1/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:00:18<\u001b[93m00:02:49\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m1/10\u001b[0m   \u001b[99m0.2190\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  10.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m                                                      |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m2/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:00:37<\u001b[93m00:02:31\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m2/10\u001b[0m   \u001b[99m0.1607\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  20.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m                                                |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m3/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:00:56<\u001b[93m00:02:11\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m3/10\u001b[0m   \u001b[99m0.1239\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  30.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m                                          |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m4/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:01:15<\u001b[93m00:01:52\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m4/10\u001b[0m   \u001b[99m0.1059\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  40.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m                                    |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m5/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:01:33<\u001b[93m00:01:33\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m5/10\u001b[0m   \u001b[99m0.0954\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  50.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m                              |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m6/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:01:52<\u001b[93m00:01:14\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m6/10\u001b[0m   \u001b[99m0.0873\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  60.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m                        |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m7/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:02:12<\u001b[93m00:00:56\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m7/10\u001b[0m   \u001b[99m0.0812\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  70.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m                  |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m8/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:02:30<\u001b[93m00:00:37\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m8/10\u001b[0m   \u001b[99m0.0769\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  80.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m            |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m9/\u001b[93m10\u001b[0m\u001b[0m   \u001b[99m00:02:49<\u001b[93m00:00:18\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m9/10\u001b[0m   \u001b[99m0.0734\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m  90.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m      |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m10/\u001b[93m10\u001b[0m\u001b[0m  \u001b[99m00:03:08<\u001b[93m00:00:00\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m10/10\u001b[0m  \u001b[99m0.0711\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m 100.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m|\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m    \u001b[1mepoch\u001b[0m   \u001b[1mloss\u001b[0m                               \n",
            " \u001b[99m10/\u001b[93m10\u001b[0m\u001b[0m  \u001b[99m00:03:08<\u001b[93m00:00:00\u001b[0m\u001b[0m  \u001b[99m0.05it/s\u001b[0m  \u001b[99m10/10\u001b[0m  \u001b[99m0.0711\u001b[0m                              \n",
            "\u001b[1mDescription\u001b[0m 100.0% |\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m\u001b[97m█\u001b[0m|"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AsTNjx5g997n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk0UxFuchLzR"
      },
      "source": [
        "# Inference\n",
        "Model is loaded and generates its anomaly score predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evgMW3OwoGqD"
      },
      "source": [
        "## Initialize\n",
        "- dataloader\n",
        "- model\n",
        "- prediction file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MBnXAswoKmq"
      },
      "source": [
        "eval_batch_size = 200\n",
        "\n",
        "# build testing dataloader\n",
        "data = torch.tensor(test, dtype=torch.float32)\n",
        "test_dataset = CustomTensorDataset(data)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=eval_batch_size, num_workers=1)\n",
        "eval_loss = nn.MSELoss(reduction='none')\n",
        "\n",
        "# load trained model\n",
        "checkpoint_path = f'last_model_{model_type}.pt'\n",
        "model = torch.load(checkpoint_path)\n",
        "model.eval()\n",
        "\n",
        "# prediction file \n",
        "out_file = 'prediction_'+str(ensemblePart)+'.csv'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomality = list()\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(test_dataloader):\n",
        "    img = data.float().cuda()\n",
        "    output = model(img)\n",
        "    \n",
        "    if model_type in ['all'] and coderType == 0:     \n",
        "      img = img[:,:,12:56,12:56]\n",
        "      img = img.contiguous().view(img.shape[0], img.shape[1]*img.shape[2]*img.shape[3])\n",
        "      a,b = output.shape\n",
        "      output = output.view(a, b//(64*64), 64, 64)\n",
        "      output = output[:,:,12:56,12:56]\n",
        "      output = output.contiguous().view(output.shape[0], -1)\n",
        "      loss = eval_loss(output, img).sum(-1)\n",
        "\n",
        "    elif model_type in ['all'] and coderType == 1:\n",
        "      img = img[:,:,12:56,12:56]\n",
        "      output = output[:,:,12:56,12:56]\n",
        "      loss = eval_loss(output, img).sum([1, 2, 3])\n",
        "\n",
        "    anomality.append(loss)\n",
        "anomality = torch.cat(anomality, axis=0)\n",
        "anomality = torch.sqrt(anomality).reshape(len(test), 1).cpu().numpy()\n",
        "\n",
        "df = pd.DataFrame(anomality, columns=['score'])\n",
        "df.to_csv(out_file, index_label = 'ID')"
      ],
      "metadata": {
        "id": "_1IxCX2iCW6V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "###   ensemble   ###\n",
        "### average csv. ###\n",
        "####################\n",
        "import csv\n",
        "with open('prediction_0.csv', newline='') as csvfile:\n",
        "  rows = list(csv.reader(csvfile))\n",
        "  #print(rows[0])\n",
        "  #print(rows[1])\n",
        "  csvfile.close()\n",
        "with open('prediction_1.csv', newline='') as csvfile:\n",
        "  table = list(csv.reader(csvfile))\n",
        "  #print(table[0])\n",
        "  #print(table[1])\n",
        "  for i in range(1,len(table)):\n",
        "    table[i][1] = (float(table[i][1])+float(rows[i][1]))/2\n",
        "    #print(table[i][1])\n",
        "  csvfile.close()\n",
        "\n",
        "csvfile = open('prediction.csv', 'w')\n",
        "writer = csv.writer(csvfile)\n",
        "writer.writerows(table)\n",
        "csvfile.close()"
      ],
      "metadata": {
        "id": "pyxa9UPXIgVC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = test_dataloader[2]\n",
        "data = np.transpose(data, (1, 2, 0))\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(data[12:56,12:56,:], aspect=\"auto\")\n",
        "#plt.show()\n",
        "plt.savefig('origin.png')\n",
        "\n",
        "#output = model(img)\n",
        "\n",
        "res = output[2].cpu().detach().numpy()\n",
        "print(res.shape)\n",
        "res = np.reshape(res, [3,44,44])\n",
        "res = np.transpose(res, (1,2,0))\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(res[12:56,12:56,:], aspect=\"auto\")\n",
        "#plt.show()\n",
        "plt.savefig('final.png')"
      ],
      "metadata": {
        "id": "1HQFbB_PcLRh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "bf7a5985-22ae-49b9-8e48-99528b6e66ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b9d4a293b391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X36MvbF-CV3N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}